{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import sys\n",
    "from numpy import arange, isscalar, asarray, array, NaN, Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sliced_NeckTotal_1 = pickle.load( open( \"Sliced_NeckTotal_1.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from get_data_vasu_anand import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining Filter Functions\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining Peak Detection functions - Returns maxidx and minidx\n",
    "def peakdet(v, delta, x = None):\n",
    "    maxtab = []\n",
    "    mintab = []\n",
    "       \n",
    "    if x is None:\n",
    "        x = np.arange(len(v))\n",
    "    \n",
    "    v = np.asarray(v)\n",
    "    \n",
    "    if len(v) != len(x):\n",
    "        sys.exit('Input vectors v and x must have same length')\n",
    "    \n",
    "    if not isscalar(delta):\n",
    "        sys.exit('Input argument delta must be a scalar')\n",
    "    \n",
    "    if delta <= 0:\n",
    "        sys.exit('Input argument delta must be positive')\n",
    "    \n",
    "    mn, mx = Inf, -Inf\n",
    "    mnpos, mxpos = NaN, NaN\n",
    "    \n",
    "    lookformax = True\n",
    "    \n",
    "    for i in np.arange(len(v)):\n",
    "        this = v[i]\n",
    "        if this > mx:\n",
    "            mx = this\n",
    "            mxpos = x[i]\n",
    "        if this < mn:\n",
    "            mn = this\n",
    "            mnpos = x[i]\n",
    "        \n",
    "        if lookformax:\n",
    "            if this < mx-delta:\n",
    "                maxtab.append((mxpos, mx))\n",
    "                mn = this\n",
    "                mnpos = x[i]\n",
    "                lookformax = False\n",
    "        else:\n",
    "            if this > mn+delta:\n",
    "                mintab.append((mnpos, mn))\n",
    "                mx = this\n",
    "                mxpos = x[i]\n",
    "                lookformax = True\n",
    "\n",
    "    return array(maxtab), array(mintab)\n",
    "\n",
    "#Automated Peak Detection\n",
    "def auto_peaks(data, npeaks, delta0):\n",
    "    npeaks_range = [npeaks*0.9,npeaks*1.1]\n",
    "    maxidx, minidx = peakdet(data,delta0,x=None) \n",
    "    \n",
    "    if len(maxidx) > npeaks_range[0]:\n",
    "        if len(maxidx) < npeaks_range[1]:\n",
    "            return maxidx, minidx\n",
    "    return auto_peaks(data,npeaks,delta0-0.02*delta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FFT\n",
    "def get_fft(sampling_rate, freq, data):\n",
    "    Fs = sampling_rate\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,30,Ts) # time vector\n",
    "\n",
    "    ff = freq;   # frequency of the signal\n",
    "    y3 = data\n",
    "\n",
    "    n = len(y3) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y3)/n # fft computing and normalization\n",
    "    Y = Y[range(int(n/2))]\n",
    "    max_abs_frq = np.where(abs(Y)==np.max(abs(Y)))\n",
    "    max_abs_frq = max_abs_frq[0][0]\n",
    "    return max_abs_frq\n",
    "\n",
    "#     frq, fft_data = get_fft(fs, fft_freq, filtered_data) \n",
    "\n",
    "def sliding_window_fft(data, maxidx, sampling_rate, fft_freq):\n",
    "    max_fft = []\n",
    "    for m in maxidx:\n",
    "        start_idx = m[0] - 1000\n",
    "        end_idx = m[0] + 1000\n",
    "        if (start_idx < 0):\n",
    "            start_idx = 0\n",
    "        if (end_idx >= len(data)):\n",
    "            end_idx = len(data)-1\n",
    "        d = data[start_idx: end_idx]\n",
    "        max_fft.append(get_fft(sampling_rate, fft_freq, d))\n",
    "    return max_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fs_find(maxidx,minidx):\n",
    "    \n",
    "    #Finding First and Second Peaks\n",
    "    first_p = []\n",
    "    second_p = []\n",
    "    \n",
    "    for i in range(1,len(maxidx)-1):\n",
    "        if i == 1:\n",
    "            if (maxidx[i][0]-maxidx[i-1][0])>(maxidx[i+1][0]-maxidx[i][0]):\n",
    "                second_p.append([maxidx[i-1][0], maxidx[i-1][1]])      \n",
    "            else:\n",
    "                first_p.append([maxidx[i-1][0], maxidx[i-1][1]])\n",
    "            \n",
    "           \n",
    "        if (maxidx[i][0]-maxidx[i-1][0])>(maxidx[i+1][0]-maxidx[i][0]):\n",
    "            if i != len(maxidx)-2:\n",
    "                first_p.append([maxidx[i][0],maxidx[i][1]])\n",
    "            else:\n",
    "                second_p.append([maxidx[i+1][0],maxidx[i+1][1]])\n",
    "          \n",
    "        else:\n",
    "            if i != len(maxidx)-2:\n",
    "                second_p.append([maxidx[i][0],maxidx[i][1]])\n",
    "            else:\n",
    "                first_p.append([maxidx[i+1][0],maxidx[i+1][1]])\n",
    "        \n",
    "    first_t = []\n",
    "    second_t = []\n",
    "    \n",
    "    for i in range(1,len(minidx)-1):\n",
    "        if i == 1:\n",
    "            if (minidx[i][0]-minidx[i-1][0])>(minidx[i+1][0]-minidx[i][0]):\n",
    "                second_t.append([minidx[i-1][0], minidx[i-1][1]])      \n",
    "            else:\n",
    "                first_t.append([minidx[i-1][0], minidx[i-1][1]])\n",
    "            \n",
    "           \n",
    "        if (minidx[i][0]-minidx[i-1][0])>(minidx[i+1][0]-minidx[i][0]):\n",
    "            if i != len(maxidx)-2:\n",
    "                first_t.append([minidx[i][0],minidx[i][1]])\n",
    "            else:\n",
    "                second_t.append([minidx[i+1][0],minidx[i+1][1]])\n",
    "          \n",
    "        else:\n",
    "            if i != len(minidx)-2:\n",
    "                second_t.append([minidx[i][0],minidx[i][1]])\n",
    "            else:\n",
    "                first_t.append([minidx[i+1][0],minidx[i+1][1]])  \n",
    "    \n",
    "   \n",
    "             \n",
    "    #Dropping outliers\n",
    "    if second_p[0][0]<first_p[0][0]:\n",
    "        second_p.remove(second_p[0][:])\n",
    "    if first_t[0][0]<first_p[0][0]:\n",
    "        first_t.remove(first_t[0][:])\n",
    "    if second_t[0][0]<first_p[0][0]:\n",
    "        second_t.remove(second_t[0][:])       \n",
    "    fp = []\n",
    "    sp = []\n",
    "    ft = []\n",
    "    st = []  \n",
    "   \n",
    "    i = 0\n",
    "    p = 0\n",
    "    q = 0\n",
    "    r = 0\n",
    "    s = 0\n",
    "\n",
    "    while i <min(len(first_p),len(second_p),len(first_t),len(second_t)):\n",
    "        \n",
    "        if (p+2)>len(first_p) or (q+1)>len(first_t) or (r+1)>len(second_p) or (s+1)>len(second_t):\n",
    "            break\n",
    "\n",
    "        if second_t[s][0]<first_p[p+1][0]:\n",
    "            if second_p[r][0]<first_p[p+1][0]:\n",
    "                if first_t[q][0]<first_p[p+1][0]:\n",
    "                    fp.append((first_p[p][0],first_p[p][1]))\n",
    "                    sp.append((second_p[r][0],second_p[r][1]))\n",
    "                    ft.append((first_t[q][0],first_t[q][1]))\n",
    "                    st.append((second_t[s][0],second_t[s][1]))\n",
    "                else:\n",
    "                    p+=1\n",
    "                    s+=1\n",
    "                    r+=1            \n",
    "            elif first_t[q][0]<first_p[p+1][0]:\n",
    "                p+=1\n",
    "                q+=1\n",
    "                s+=1\n",
    "            else: \n",
    "                p+=1\n",
    "                s+=1\n",
    "        else:\n",
    "                         \n",
    "            if second_p[r][0]<first_p[p+1][0]:\n",
    "                r+=1\n",
    "            if first_t[q][0]<first_p[p+1][0]:\n",
    "                q+=1  \n",
    "            p+=1\n",
    "                \n",
    "        i+=1\n",
    "        p+=1\n",
    "        q+=1\n",
    "        r+=1\n",
    "        s+=1\n",
    "\n",
    "        \n",
    "       \n",
    "    return np.asarray(fp), np.asarray(sp), np.asarray(ft), np.asarray(st)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_between_points(arr):\n",
    "    dist = []\n",
    "    if (len(arr) > 1):\n",
    "        i = 1\n",
    "        while i < len(arr):\n",
    "            d = arr[i] - arr[i-1]\n",
    "            dist.append(d)\n",
    "            i+=1\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_features(data,lowcut,highcut,order,BPM,time):\n",
    "\n",
    "    filtered_data = butter_bandpass_filter(data, lowcut, highcut, 10240, order)\n",
    "    \n",
    "    \n",
    "    \n",
    "    npeaks = BPM*2*(time/60)\n",
    "    delta0 = 2.5*np.amax(data)\n",
    " \n",
    "    #peak detection\n",
    "    peakdet_data = filtered_data\n",
    "    maxidx, minidx = auto_peaks(peakdet_data,npeaks,delta0)\n",
    "    first_peaks, second_peaks,first_troughs, second_troughs = fs_find(maxidx,minidx)\n",
    "    \n",
    "    if len(maxidx) > len(minidx):\n",
    "        maxidx = maxidx[0:len(minidx)]\n",
    "        \n",
    "    elif len(maxidx) < len(minidx):\n",
    "        minidx = minidx[0:len(maxidx)]\n",
    "         \n",
    "    #Get FFT could go here\n",
    "    fft = sliding_window_fft(filtered_data, maxidx, 10240, 6)\n",
    "\n",
    "    #first and second peak indices\n",
    "    first_peaks_x = first_peaks[:,0]\n",
    "    second_peaks_x = second_peaks[:,0]\n",
    "    first_peaks_y = first_peaks[:,1]\n",
    "    second_peaks_y = second_peaks[:,1]\n",
    "    first_troughs_x = first_troughs[:,0]\n",
    "    second_troughs_x = second_troughs[:,0]\n",
    "    first_troughs_y = first_troughs[:,1]\n",
    "    second_troughs_y = second_troughs[:,1]\n",
    "     \n",
    "    #distances between indices of first_peaks, second_peaks and maxidx peaks\n",
    "    #Peak1amp = np.median(first_peaks_y)\n",
    "    #Peak2amp = np.median(second_peaks_y)\n",
    "    #Trough1amp = np.median(first_troughs_y)\n",
    "    #Trough2amp = np.median(second_troughs_y)\n",
    "    \n",
    "    Peak1Trough1 = np.zeros(min(len(first_peaks),len(first_troughs),len(second_troughs),len(second_peaks)))\n",
    "    Peak1Trough2 = np.zeros(min(len(first_peaks),len(first_troughs),len(second_troughs),len(second_peaks)))\n",
    "    Peak1Peak2 = np.zeros(min(len(first_peaks),len(first_troughs),len(second_troughs),len(second_peaks)))\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    while i < min(len(first_peaks),len(first_troughs),len(second_troughs),len(second_peaks),len(fft)):\n",
    "        Peak1Trough1[i] = first_peaks_x[i]-first_troughs_x[i]\n",
    "        Peak1Trough2[i] = first_peaks_x[i]-second_troughs_x[i]\n",
    "        Peak1Peak2[i] = first_peaks_x[i]-second_peaks_x[i]\n",
    "        \n",
    "        i+=1   \n",
    "    \n",
    "    #p1t1 = np.mean(Peak1Trough1)\n",
    "    #p1t2 = np.mean(Peak1Trough2)\n",
    "    #p1p2 = np.mean(Peak1Peak2)\n",
    "    \n",
    "    limit = min(len(first_peaks),len(first_troughs),len(second_troughs),len(second_peaks),len(fft))\n",
    "    fft = fft[0:limit]\n",
    "    first_peaks_y = first_peaks_y[0:limit]\n",
    "    first_troughs_y = first_troughs_y[0:limit]\n",
    "    second_peaks_y = second_peaks_y[0:limit]\n",
    "    second_troughs_y = second_troughs_y[0:limit]\n",
    "    \n",
    "         \n",
    "    return np.asarray(fft),first_peaks_y, first_troughs_y,second_peaks_y,second_troughs_y, Peak1Trough1,Peak1Trough2,Peak1Peak2 #first_peaks,second_peaks,first_troughs,second_troughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['aravind','Balaji','Isabella','kim','Lobna','thomas','vasu']\n",
    "#Stuff I want\n",
    "\n",
    "things = []\n",
    "#aravind\n",
    "things.append([0,0,76800])\n",
    "things.append([1,0,55000])\n",
    "things.append([2,8000,31000])\n",
    "things.append([3,0,45000])\n",
    "things.append([4,0,76800])\n",
    "#things.extend([5,0,76800])#\n",
    "#things.extend([6,0,76800])#\n",
    "#things.extend([7,])#\n",
    "#things.extend([8,])\n",
    "things.append([9,0,76800])\n",
    "\n",
    "#Balaji\n",
    "things.append([10,35000,76800])\n",
    "#things.extend([1,])\n",
    "#things.extend([2,])\n",
    "things.append([13,0,76800])\n",
    "things.append([14,0,21000])\n",
    "things.append([15,10000,38000])\n",
    "things.append([16,0,35000])\n",
    "things.append([17,0,76800])\n",
    "things.append([18,5000,76800])\n",
    "things.append([19,0,55000])\n",
    "\n",
    "#Coral\n",
    "#things.extend([0,])\n",
    "#things.extend([1,])\n",
    "#things.extend([2,])\n",
    "#things.extend([3,])\n",
    "#things.extend([4,])\n",
    "#things.extend([5,])\n",
    "#things.extend([6,])\n",
    "#things.extend([7,])\n",
    "#things.extend([8,])\n",
    "#things.extend([9,])\n",
    "\n",
    "#Isabella\n",
    "things.append([30,0,31000])\n",
    "things.append([31,0,10000])\n",
    "things.append([32,35000,76800])\n",
    "things.append([33,8000,38000])\n",
    "things.append([34,0,28000])\n",
    "things.append([35,0,76800])\n",
    "things.append([36,17000,58000])\n",
    "things.append([37,0,30000])\n",
    "things.append([38,0,40000])\n",
    "#things.extend([39,])\n",
    "\n",
    "#kim\n",
    "things.append([40,31000,58000])\n",
    "things.append([41,0,30000])\n",
    "things.append([42,33000,52000])\n",
    "#things.append([43,0,15000])\n",
    "#things.extend([44,])\n",
    "#things.append([45,63000,70000])\n",
    "things.append([46,15000,76800])\n",
    "#things.extend([47,])\n",
    "things.append([48,42000,62000])\n",
    "#things.extend([49,])\n",
    "\n",
    "#Lobna\n",
    "#things.extend([50,])\n",
    "#things.extend([51,])\n",
    "#things.extend([52,])\n",
    "#things.extend([53,])\n",
    "#things.extend([54,])\n",
    "things.append([55,40000,45000])\n",
    "things.append([56,25000,32000])\n",
    "#things.extend([57,])\n",
    "things.append([58,0,40000])\n",
    "things.append([59,18000,30000])\n",
    "\n",
    "#nathan\n",
    "#things.extend([60,])\n",
    "#things.extend([61,])\n",
    "#things.extend([62,])\n",
    "#things.extend([63,])\n",
    "#things.extend([64,])\n",
    "#things.extend([65,])\n",
    "#things.extend([66,])\n",
    "#things.extend([67,])\n",
    "#things.extend([68,])\n",
    "#things.extend([69,])\n",
    "\n",
    "#thomas\n",
    "things.append([70,0,72000])\n",
    "things.append([71,0,72000])\n",
    "things.append([72,0,76800])\n",
    "things.append([73,28000,68000])\n",
    "things.append([74,8000,32000])\n",
    "#things.extend([75,])\n",
    "#things.extend([76,])\n",
    "things.append([77,0,22000])\n",
    "things.append([78,0,24000])\n",
    "#things.extend([79,])\n",
    "\n",
    "#Vasu\n",
    "things.append([1,0,120000])\n",
    "things.append([2,0,130000])\n",
    "things.append([3,0,70000])\n",
    "things.append([4,60000,307200])\n",
    "things.append([5,70000,210000])\n",
    "things.append([16,0,180000])\n",
    "things.append([17,18000,307200])\n",
    "things.append([18,50000,280000])\n",
    "things.append([19,50000,180000])\n",
    "things.append([20,0,307200])\n",
    "\n",
    "#anand\n",
    "#things.extend([6,])\n",
    "#things.extend([7,])\n",
    "#things.extend([8,])\n",
    "#things.extend([9,])\n",
    "#things.extend([10,])\n",
    "#things.extend([11,])\n",
    "#things.extend([12,])\n",
    "#things.extend([13,])\n",
    "#things.extend([14,])\n",
    "#things.extend([15,])\n",
    "\n",
    "things = np.asarray(things)\n",
    "\n",
    "type(things[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data, Labels and Time\n",
    "Data = []\n",
    "Y_mean = np.zeros(len(things))\n",
    "time = []\n",
    "c = 0\n",
    "for i in range(len(things)-10):\n",
    "    Data.append(Sliced_NeckTotal_1[things[i][0]][things[i][1]:things[i][2]])\n",
    "    Y_mean[i] = c\n",
    "    if int(things[i+1][0]/10)!= int(things[i][0]/10):\n",
    "        c+=1\n",
    "    time.append((30/76800)*(things[i][2]-things[i][1]))\n",
    "    \n",
    "     \n",
    "    \n",
    "for i in range(len(things)-10,len(things)):\n",
    "    Data.append(get_neck_data(things[i][0])[things[i][1]:things[i][2]])\n",
    "    Y_mean[i] = 6\n",
    "    time.append((30/307200)*(things[i][2]-things[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#BPMS:\n",
    "BPMold = [75,75,76,78,75,76,75,80,80,78] #Aravind \n",
    "BPMold.extend([85,80,77,80,81,82,84,80,83,86]) #Balaji\n",
    "BPMold.extend([0,0,0,0,0,0,0,0,0,0])#Coral\n",
    "BPMold.extend([73,74,74,73,74,73,72,85,94,92]) #Isabella\n",
    "BPMold.extend([60,57,57,60,60,65,62,62,60,59]) #Kim\n",
    "BPMold.extend([74,74,80,78,85,86,82,82,86,84]) #Lobna\n",
    "BPMold.extend([0,0,0,0,0,0,0,0,0,0])#Nathan\n",
    "BPMold.extend([62,68,61,66,64,65,67,65,66,67]) #Thomas\n",
    "BPMold.extend([64,64,64,64,64,64,64,64,64,64]) #Vasu\n",
    "\n",
    "BPMold = np.asarray(BPMold)\n",
    "BPM = np.zeros(len(things))\n",
    "\n",
    "for i in range(len(things)-10):\n",
    "    BPM[i] = BPMold[things[i][0]]\n",
    "    \n",
    "for i in range(len(things)-10,len(things)):\n",
    "    BPM[i] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUCESS\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:33: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#INPUT - get_all_features(data,lowcut,highcut,order,BPM,time):\n",
    "#OUTPUT (8) - fft,first_peaks_y, first_troughs_y,second_peaks_y,second_troughs_y, Peak1Trough1,Peak1Trough2,Peak1Peak2,first_peaks,second_peaks,first_troughs,second_troughs\n",
    "X =[]\n",
    "Y = []\n",
    "X_mean = np.zeros((len(things),8))\n",
    "X_median = np.zeros((len(things),8))\n",
    "\n",
    "for i in range(len(Data)):\n",
    "    \n",
    "    \n",
    "    print (i)\n",
    "    a,b,c,d,e,f,g,h = get_all_features(Data[i],10,90,2,BPM[i],time[i])\n",
    "    \n",
    "    limit = min(len(a),len(b),len(c),len(d),len(e),len(f),len(g),len(h))\n",
    "    \n",
    "    for item in range(limit):\n",
    "        X.append([a[item],b[item],c[item],d[item],e[item],f[item],g[item],h[item]])\n",
    "        Y.append(Y_mean[i])\n",
    " \n",
    "    \n",
    "    X_mean[i][0]=np.mean(a)\n",
    "    X_median[i][0] = np.median(a)\n",
    "    X_mean[i][1]=np.mean(b)\n",
    "    X_median[i][1] = np.median(b)\n",
    "    X_mean[i][2]=np.mean(c)\n",
    "    X_median[i][2] = np.median(c)\n",
    "    X_mean[i][3]=np.mean(d)\n",
    "    X_median[i][3] = np.median(d)\n",
    "    X_mean[i][4]=np.mean(e)\n",
    "    X_median[i][4] = np.median(e)\n",
    "    X_mean[i][5]=np.mean(f)\n",
    "    X_median[i][5] = np.median(f)\n",
    "    X_mean[i][6]=np.mean(g)\n",
    "    X_median[i][6] = np.median(g)\n",
    "    X_mean[i][7]=np.mean(h)\n",
    "    X_median[i][7] = np.median(h)\n",
    "\n",
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  4.00000000e+00,   1.46941559e-02,  -2.46062298e-02, ...,\n",
       "         -8.50000000e+01,  -7.58000000e+02,  -6.80000000e+02],\n",
       "       [  5.00000000e+00,   1.83763811e-02,  -2.95053142e-02, ...,\n",
       "         -9.20000000e+01,  -7.48000000e+02,  -6.67000000e+02],\n",
       "       [  5.00000000e+00,   1.70165884e-02,  -2.65705800e-02, ...,\n",
       "         -2.11000000e+03,  -8.50000000e+01,  -6.71000000e+02],\n",
       "       ..., \n",
       "       [  2.00000000e+00,   1.59287346e-02,  -2.08863047e-02, ...,\n",
       "         -2.25000000e+02,  -2.91900000e+03,  -2.77100000e+03],\n",
       "       [  2.00000000e+00,   1.28419425e-02,  -1.98056323e-02, ...,\n",
       "         -2.38000000e+02,  -2.94300000e+03,  -2.79500000e+03],\n",
       "       [  5.00000000e+00,   1.18203324e-02,  -2.02321686e-02, ...,\n",
       "         -1.97000000e+02,  -3.00200000e+03,  -2.85300000e+03]])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "print (X.shape)\n",
    "Y = np.asarray(Y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(X, open( \"X_Neck.p\", \"wb\" ))\n",
    "pickle.dump(Y, open( \"Y_Neck.p\", \"wb\" ))\n",
    "pickle.dump(X_median, open( \"X_median_Neck.p\", \"wb\" ))\n",
    "pickle.dump(Y_median, open( \"Y_median_Neck.p\", \"wb\" ))\n",
    "pickle.dump(X_mean, open( \"X_mean_Neck.p\", \"wb\" ))\n",
    "pickle.dump(Y_mean, open( \"Y_mean_Neck.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_median, Y_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71428571  0.85714286  0.71428571  0.28571429  0.5         0.8         0.5\n",
      "  1.          0.5         1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUCESS\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:516: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_mean, Y_mean, cv = 10)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
